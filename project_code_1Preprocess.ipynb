{
 "cells": [
  {
   "cell_type": "code",
   "id": "e623a02d",
   "metadata": {
    "id": "e623a02d",
    "outputId": "3b65cb56-0783-441f-ea70-20f9f2062ee1",
    "ExecuteTime": {
     "end_time": "2025-12-27T14:27:15.343807Z",
     "start_time": "2025-12-27T14:26:31.299377100Z"
    }
   },
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "\n",
    "\n",
    "def parse_fasttext(path):\n",
    "    \"\"\"Parse fastText-like or TSV lines into a DataFrame with `label` and `text`.\n",
    "    Supports lines starting with __label__LABEL text..., or tab-separated label\\ttext, or 'LABEL text'.\"\"\"\n",
    "    labels = []\n",
    "    texts = []\n",
    "    p = Path(path)\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f\"File not found: {path}\")\n",
    "    with p.open('r', encoding='utf-8', errors='ignore') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            if line.startswith('__label__'):\n",
    "                parts = line.split()\n",
    "                label = parts[0].replace('__label__', '')\n",
    "                text = ' '.join(parts[1:]) if len(parts) > 1 else ''\n",
    "            elif '\\t' in line:\n",
    "                label, text = line.split('\\t', 1)\n",
    "            else:\n",
    "                parts = line.split()\n",
    "                label = parts[0] if parts else ''\n",
    "                text = ' '.join(parts[1:]) if len(parts) > 1 else ''\n",
    "            labels.append(label)\n",
    "            texts.append(text)\n",
    "    return pd.DataFrame({'label': labels, 'text': texts})\n",
    "\n",
    "\n",
    "\n",
    "def clean_text(s: str) -> str:\n",
    "    if not isinstance(s, str):\n",
    "        return ''\n",
    "    s = s.lower()\n",
    "    s = re.sub(r'http\\S+', ' ', s)\n",
    "    s = re.sub(r'<[^>]+>', ' ', s)\n",
    "    s = re.sub(r\"[^a-z0-9\\s']\", ' ', s)\n",
    "    s = re.sub(r\"\\s+\", ' ', s).strip()\n",
    "    return s\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_df(df, text_col='text', label_col='label', do_lemmatize=False):\n",
    "    \"\"\"Apply cleaning, add tokens/lengths, and optionally lemmatize (requires spaCy).\n",
    "    Returns a copy with `text_clean`, `tokens`, and `length` columns.\"\"\"\n",
    "    out = df.copy()\n",
    "    out['text_clean'] = out[text_col].fillna('').astype(str).map(clean_text)\n",
    "    out['length'] = out['text_clean'].str.len()\n",
    "\n",
    "\n",
    "    out['tokens'] = out['text_clean'].str.split()\n",
    "\n",
    "    if do_lemmatize:\n",
    "        try:\n",
    "            import spacy\n",
    "            nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "            def lemmatize_list(tokens):\n",
    "                doc = nlp(' '.join(tokens))\n",
    "                return [t.lemma_ for t in doc]\n",
    "            out['lemmas'] = out['tokens'].map(lemmatize_list)\n",
    "        except Exception as e:\n",
    "            print('spaCy lemmatization unavailable:', e)\n",
    "            out['lemmas'] = out['tokens']\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "def save_cleaned(df, path='cleaned_data.csv'):\n",
    "    df.to_csv(path, index=False)\n",
    "    print(f'Saved cleaned data to {path}')\n",
    "\n",
    "def save_splits(df, label_col='label', test_size=0.2, random_state=42,\n",
    "                out_dir='splits'):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X = df\n",
    "    y = df[label_col].fillna('')\n",
    "    stratify = y if y.nunique() > 1 else None\n",
    "    X_train, X_val = train_test_split(X, test_size=test_size, random_state=random_state, stratify=stratify)\n",
    "    d = Path(out_dir)\n",
    "    d.mkdir(exist_ok=True)\n",
    "    train_path = d / 'train.csv'\n",
    "    val_path = d / 'validation.csv'\n",
    "    X_train.to_csv(train_path, index=False)\n",
    "    X_val.to_csv(val_path, index=False)\n",
    "    print(f'Saved train ({len(X_train)}) -> {train_path} and validation ({len(X_val)}) -> {val_path}')\n",
    "    return train_path, val_path\n",
    "\n",
    "\n",
    "df = parse_fasttext('test.ft.txt')\n",
    "print(df.shape)\n",
    "print(df['label'].value_counts())\n",
    "df_clean = preprocess_df(df, do_lemmatize=False)\n",
    "display(df_clean.head())\n",
    "save_cleaned(df_clean, 'cleaned_data.csv')\n",
    "save_splits(df_clean, out_dir='splits')\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400000, 2)\n",
      "label\n",
      "2    200000\n",
      "1    200000\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  label                                               text  \\\n",
       "0     2  Great CD: My lovely Pat has one of the GREAT v...   \n",
       "1     2  One of the best game music soundtracks - for a...   \n",
       "2     1  Batteries died within a year ...: I bought thi...   \n",
       "3     2  works fine, but Maha Energy is better: Check o...   \n",
       "4     2  Great for the non-audiophile: Reviewed quite a...   \n",
       "\n",
       "                                          text_clean  length  \\\n",
       "0  great cd my lovely pat has one of the great vo...     513   \n",
       "1  one of the best game music soundtracks for a g...     798   \n",
       "2  batteries died within a year i bought this cha...     323   \n",
       "3  works fine but maha energy is better check out...     221   \n",
       "4  great for the non audiophile reviewed quite a ...     403   \n",
       "\n",
       "                                              tokens  \n",
       "0  [great, cd, my, lovely, pat, has, one, of, the...  \n",
       "1  [one, of, the, best, game, music, soundtracks,...  \n",
       "2  [batteries, died, within, a, year, i, bought, ...  \n",
       "3  [works, fine, but, maha, energy, is, better, c...  \n",
       "4  [great, for, the, non, audiophile, reviewed, q...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>length</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Great CD: My lovely Pat has one of the GREAT v...</td>\n",
       "      <td>great cd my lovely pat has one of the great vo...</td>\n",
       "      <td>513</td>\n",
       "      <td>[great, cd, my, lovely, pat, has, one, of, the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>One of the best game music soundtracks - for a...</td>\n",
       "      <td>one of the best game music soundtracks for a g...</td>\n",
       "      <td>798</td>\n",
       "      <td>[one, of, the, best, game, music, soundtracks,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Batteries died within a year ...: I bought thi...</td>\n",
       "      <td>batteries died within a year i bought this cha...</td>\n",
       "      <td>323</td>\n",
       "      <td>[batteries, died, within, a, year, i, bought, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>works fine, but Maha Energy is better: Check o...</td>\n",
       "      <td>works fine but maha energy is better check out...</td>\n",
       "      <td>221</td>\n",
       "      <td>[works, fine, but, maha, energy, is, better, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Great for the non-audiophile: Reviewed quite a...</td>\n",
       "      <td>great for the non audiophile reviewed quite a ...</td>\n",
       "      <td>403</td>\n",
       "      <td>[great, for, the, non, audiophile, reviewed, q...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned data to cleaned_data.csv\n",
      "Saved train (320000) -> splits\\train.csv and validation (80000) -> splits\\validation.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(WindowsPath('splits/train.csv'), WindowsPath('splits/validation.csv'))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
