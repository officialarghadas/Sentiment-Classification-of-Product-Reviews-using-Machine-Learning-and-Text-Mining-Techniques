{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07428e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from scipy.sparse import hstack, save_npz, load_npz, csr_matrix\n",
    "from sklearn.svm import LinearSVC\n",
    "print(\"Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57aca699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing complete. Train: (320000, 5), Val: (80000, 5)\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing: Load data, clean text, create splits\n",
    "def clean_text(s):\n",
    "    s = (s or \"\").lower()\n",
    "    s = re.sub(r'http\\\\S+|<[^>]+>', ' ', s)\n",
    "    s = re.sub(r\"[^a-z0-9\\\\s']\", ' ', s)\n",
    "    return re.sub(r\"\\\\s+\", ' ', s).strip()\n",
    "\n",
    "\n",
    "p = Path('test.ft.txt')\n",
    "if p.exists():\n",
    "    text = p.read_text(encoding='utf-8', errors='replace')\n",
    "    lines = [l.strip() for l in text.splitlines() if l.strip()]\n",
    "    rows = []\n",
    "    for l in lines:\n",
    "        if ' ' in l:\n",
    "            label_token, review = l.split(' ', 1)\n",
    "        else:\n",
    "            label_token, review = l, ''\n",
    "        m = re.match(r\"__label__([0-9]+)\", label_token)\n",
    "        label = int(m.group(1)) if m else label_token\n",
    "        rows.append({'label': label, 'text': review})\n",
    "    df = pd.DataFrame(rows)\n",
    "    df['text_clean'] = df['text'].apply(clean_text)\n",
    "    df['length'] = df['text_clean'].str.len()\n",
    "    df['tokens'] = df['text_clean'].str.split()\n",
    "    \n",
    "  \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    train_df, val_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['label'])\n",
    "    Path('splits').mkdir(exist_ok=True)\n",
    "    train_df.to_csv('splits/train.csv', index=False)\n",
    "    val_df.to_csv('splits/validation.csv', index=False)\n",
    "    print(f\"Preprocessing complete. Train: {train_df.shape}, Val: {val_df.shape}\")\n",
    "else:\n",
    "    print(\"test.ft.txt not found. Please place the file in the notebook directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c02c4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features saved. Train shape: (320000, 1222610), Val shape: (80000, 1222610)\n"
     ]
    }
   ],
   "source": [
    "# Feature Engineering: TF-IDF + Lexical features\n",
    "feature_dir = Path('features')\n",
    "feature_dir.mkdir(exist_ok=True)\n",
    "\n",
    "\n",
    "def extract_lexical_features(df):\n",
    "    features = pd.DataFrame()\n",
    "    features['char_count'] = df['text_clean'].str.len()\n",
    "    features['word_count'] = df['text_clean'].str.split().str.len()\n",
    "    features['avg_word_length'] = features['char_count'] / (features['word_count'] + 1)\n",
    "    features['exclamation_count'] = df['text_clean'].str.count('!')\n",
    "    features['question_count'] = df['text_clean'].str.count('\\\\?')\n",
    "    return features\n",
    "\n",
    "train_lexical = extract_lexical_features(train_df)\n",
    "val_lexical = extract_lexical_features(val_df)\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2), min_df=2, max_df=0.95, stop_words='english')\n",
    "X_train_tfidf = vectorizer.fit_transform(train_df['text_clean'])\n",
    "X_val_tfidf = vectorizer.transform(val_df['text_clean'])\n",
    "\n",
    "\n",
    "train_lexical_sparse = csr_matrix(train_lexical.values)\n",
    "val_lexical_sparse = csr_matrix(val_lexical.values)\n",
    "X_train = hstack([X_train_tfidf, train_lexical_sparse])\n",
    "X_val = hstack([X_val_tfidf, val_lexical_sparse])\n",
    "\n",
    "\n",
    "save_npz(feature_dir / 'tfidf_lex_combined_train.npz', X_train)\n",
    "save_npz(feature_dir / 'tfidf_lex_combined_val.npz', X_val)\n",
    "np.save(feature_dir / 'train_labels.npy', train_df['label'].values)\n",
    "np.save(feature_dir / 'val_labels.npy', val_df['label'].values)\n",
    "with open(feature_dir / 'tfidf_vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(vectorizer, f)\n",
    "\n",
    "print(f\"Features saved. Train shape: {X_train.shape}, Val shape: {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa8a33fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Results:\n",
      "Accuracy: 0.7706\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.77      0.77     40000\n",
      "           2       0.77      0.78      0.77     40000\n",
      "\n",
      "    accuracy                           0.77     80000\n",
      "   macro avg       0.77      0.77      0.77     80000\n",
      "weighted avg       0.77      0.77      0.77     80000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model 1: Decision Tree\n",
    "# Toggle tuning: set to True to run GridSearchCV, False to train default estimator\n",
    "RUN_DT_TUNING = False\n",
    "\n",
    "if RUN_DT_TUNING:\n",
    "    dt_params = {\n",
    "        \"max_depth\": [None, 10, 20, 30],\n",
    "        \"min_samples_split\": [2, 5, 10]\n",
    "    }\n",
    "\n",
    "    dt_grid = GridSearchCV(\n",
    "        DecisionTreeClassifier(criterion=\"gini\", random_state=42),\n",
    "        dt_params,\n",
    "        cv=3, \n",
    "        scoring=\"accuracy\"\n",
    "    )\n",
    "\n",
    "    dt_grid.fit(X_train, train_df['label'])\n",
    "    print(\"Best Params:\", dt_grid.best_params_)\n",
    "    best_dt = dt_grid.best_estimator_\n",
    "else:\n",
    "    best_dt = DecisionTreeClassifier(criterion=\"gini\", random_state=42)\n",
    "    best_dt.fit(X_train, train_df['label'])\n",
    "\n",
    "# Evaluation\n",
    "y_pred_dt = best_dt.predict(X_val)\n",
    "print(\"Decision Tree Results:\")\n",
    "print(f\"Accuracy: {accuracy_score(val_df['label'], y_pred_dt):.4f}\")\n",
    "print(classification_report(val_df['label'], y_pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "351bce13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Results:\n",
      "Accuracy: 0.8960\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.90      0.89      0.90     40000\n",
      "           2       0.89      0.90      0.90     40000\n",
      "\n",
      "    accuracy                           0.90     80000\n",
      "   macro avg       0.90      0.90      0.90     80000\n",
      "weighted avg       0.90      0.90      0.90     80000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ibrah\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Model 2: Logistic Regression\n",
    "# Toggle tuning: set to True to run GridSearchCV, False to train default estimator\n",
    "RUN_LR_TUNING = False\n",
    "\n",
    "if RUN_LR_TUNING:\n",
    "    lr_params = {\n",
    "        \"C\": [0.01, 0.1, 1, 10]\n",
    "    }\n",
    "\n",
    "    lr_grid = GridSearchCV(\n",
    "        LogisticRegression(max_iter=1000),\n",
    "        lr_params,\n",
    "        cv=3,  \n",
    "        scoring=\"accuracy\"\n",
    "    )\n",
    "\n",
    "    lr_grid.fit(X_train, train_df['label'])\n",
    "    print(\"Best Params:\", lr_grid.best_params_)\n",
    "    best_lr = lr_grid.best_estimator_\n",
    "else:\n",
    "    best_lr = LogisticRegression(max_iter=1000)\n",
    "    best_lr.fit(X_train, train_df['label'])\n",
    "\n",
    "# Evaluation\n",
    "y_pred_lr = best_lr.predict(X_val)\n",
    "print(\"Logistic Regression Results:\")\n",
    "print(f\"Accuracy: {accuracy_score(val_df['label'], y_pred_lr):.4f}\")\n",
    "print(classification_report(val_df['label'], y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7530c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Results:\n",
      "Accuracy: 0.8640\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.92      0.80      0.85     40000\n",
      "           2       0.82      0.93      0.87     40000\n",
      "\n",
      "    accuracy                           0.86     80000\n",
      "   macro avg       0.87      0.86      0.86     80000\n",
      "weighted avg       0.87      0.86      0.86     80000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ibrah\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Model 3: SVM\n",
    "# Toggle tuning: set to True to run GridSearchCV, False to train a fast linear SVM\n",
    "RUN_SVM_TUNING = False\n",
    "\n",
    "if RUN_SVM_TUNING:\n",
    "    svm_params = {\n",
    "        \"C\": [0.1, 1, 10],\n",
    "        \"kernel\": [\"linear\", \"rbf\"]\n",
    "    }\n",
    "\n",
    "    svm_grid = GridSearchCV(\n",
    "        SVC(),\n",
    "        svm_params,\n",
    "        cv=3,  \n",
    "        scoring=\"accuracy\"\n",
    "    )\n",
    "\n",
    "    svm_grid.fit(X_train, train_df['label'])\n",
    "    print(\"Best Params:\", svm_grid.best_params_)\n",
    "    best_svm = svm_grid.best_estimator_\n",
    "else:\n",
    "    from sklearn.svm import LinearSVC\n",
    "    best_svm = LinearSVC(max_iter=2000)\n",
    "    best_svm.fit(X_train, train_df['label'])\n",
    "\n",
    "# Evaluation\n",
    "y_pred_svm = best_svm.predict(X_val)\n",
    "print(\"SVM Results:\")\n",
    "print(f\"Accuracy: {accuracy_score(val_df['label'], y_pred_svm):.4f}\")\n",
    "print(classification_report(val_df['label'], y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eef25983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Results:\n",
      "Accuracy: 0.7279\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.83      0.75     40000\n",
      "           2       0.79      0.63      0.70     40000\n",
      "\n",
      "    accuracy                           0.73     80000\n",
      "   macro avg       0.74      0.73      0.73     80000\n",
      "weighted avg       0.74      0.73      0.73     80000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model 4: AdaBoost\n",
    "# Toggle tuning: set to True to run GridSearchCV, False to train default estimator\n",
    "RUN_ADA_TUNING = False\n",
    "\n",
    "if RUN_ADA_TUNING:\n",
    "    ada_params = {\n",
    "        \"n_estimators\": [50, 100, 200],\n",
    "        \"learning_rate\": [0.01, 0.1, 1]\n",
    "    }\n",
    "\n",
    "    ada_grid = GridSearchCV(\n",
    "        AdaBoostClassifier(random_state=42),\n",
    "        ada_params,\n",
    "        cv=3,  \n",
    "        scoring=\"accuracy\"\n",
    "    )\n",
    "\n",
    "    ada_grid.fit(X_train, train_df['label'])\n",
    "    print(\"Best Params:\", ada_grid.best_params_)\n",
    "    best_ada = ada_grid.best_estimator_\n",
    "else:\n",
    "    best_ada = AdaBoostClassifier(random_state=42)\n",
    "    best_ada.fit(X_train, train_df['label'])\n",
    "\n",
    "# Evaluation\n",
    "y_pred_ada = best_ada.predict(X_val)\n",
    "print(\"AdaBoost Results:\")\n",
    "print(f\"Accuracy: {accuracy_score(val_df['label'], y_pred_ada):.4f}\")\n",
    "print(classification_report(val_df['label'], y_pred_ada))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f62f24fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decision Tree Predictions:\n",
      "  'This product is amazing! I love it so much.' -> Positive (label: 2)\n",
      "  'Terrible quality, I regret buying this.' -> Negative (label: 1)\n",
      "  'It's okay, nothing special.' -> Negative (label: 1)\n",
      "\n",
      "Logistic Regression Predictions:\n",
      "  'This product is amazing! I love it so much.' -> Positive (label: 2)\n",
      "  'Terrible quality, I regret buying this.' -> Negative (label: 1)\n",
      "  'It's okay, nothing special.' -> Negative (label: 1)\n",
      "\n",
      "SVM Predictions:\n",
      "  'This product is amazing! I love it so much.' -> Positive (label: 2)\n",
      "  'Terrible quality, I regret buying this.' -> Negative (label: 1)\n",
      "  'It's okay, nothing special.' -> Negative (label: 1)\n",
      "\n",
      "AdaBoost Predictions:\n",
      "  'This product is amazing! I love it so much.' -> Positive (label: 2)\n",
      "  'Terrible quality, I regret buying this.' -> Negative (label: 1)\n",
      "  'It's okay, nothing special.' -> Negative (label: 1)\n"
     ]
    }
   ],
   "source": [
    "# Prediction Pipeline: Predict sentiment on new text using the trained models\n",
    "\n",
    "new_texts = [\n",
    "    \"This product is amazing! I love it so much.\",\n",
    "    \"Terrible quality, I regret buying this.\",\n",
    "    \"It's okay, nothing special.\"\n",
    "]\n",
    "\n",
    "\n",
    "new_df = pd.DataFrame({'text': new_texts})\n",
    "new_df['text_clean'] = new_df['text'].apply(clean_text)\n",
    "new_df['length'] = new_df['text_clean'].str.len()\n",
    "new_df['tokens'] = new_df['text_clean'].str.split()\n",
    "\n",
    "\n",
    "new_lexical = extract_lexical_features(new_df)\n",
    "new_tfidf = vectorizer.transform(new_df['text_clean'])\n",
    "new_lexical_sparse = csr_matrix(new_lexical.values)\n",
    "X_new = hstack([new_tfidf, new_lexical_sparse])\n",
    "\n",
    "\n",
    "models = {\n",
    "    \"Decision Tree\": best_dt,\n",
    "    \"Logistic Regression\": best_lr,\n",
    "    \"SVM\": best_svm,\n",
    "    \"AdaBoost\": best_ada\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    predictions = model.predict(X_new)\n",
    "    print(f\"\\n{name} Predictions:\")\n",
    "    for text, pred in zip(new_texts, predictions):\n",
    "        sentiment = \"Positive\" if pred == 2 else \"Negative\"  \n",
    "        print(f\"  '{text}' -> {sentiment} (label: {pred})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
